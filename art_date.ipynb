{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Art Dating\n",
    "\n",
    "#### Students\n",
    "- Zhenbang Chen\n",
    "- Zhenjia Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Importing packages and dependencies.  Load dataset for categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "rootpath = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# You might not have tqdm, which gives you nice progress bars\n",
    "!pip install tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, resume_from=None):\n",
    "    \n",
    "    # Model (nn.Module) to return\n",
    "    # model_ft = models.resnet18(pretrained = false)\n",
    "    model_ft = models.resnet50(pretrained = true)\n",
    "    \n",
    "    in_features = 512\n",
    "    model_ft.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to apply to the data\n",
    "# transform = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "#     torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "# ])\n",
    "\n",
    "# Transform to apply to the data for use with pretrained ResNet model\n",
    "transform = torchvision.transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data from directory\n",
    "art_train = torchvision.datasets.ImageFolder(root=\"./data/art_train\",\n",
    "                                                 transform=transform)\n",
    "\n",
    "# Get testing data from directory\n",
    "art_val = torchvision.datasets.ImageFolder(root=\"./data/art_val\",\n",
    "                                               transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random sampler\n",
    "random_sampler = torch.utils.data.RandomSampler(data_source=art_train,\n",
    "                                                replacement=True,\n",
    "                                                num_samples=int(len(letters_train)/20))\n",
    "\n",
    "# Create batched dataloader\n",
    "art_train_loader = torch.utils.data.DataLoader(dataset=art_train,\n",
    "                                                   batch_size=512,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=4,\n",
    "                                                   pin_memory=True)\n",
    "\n",
    "art_val_loader = torch.utils.data.DataLoader(dataset=art_val,\n",
    "                                                 batch_size=512,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=4,\n",
    "                                                 pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "# model = torchvision.models.resnet18(pretrained=False)\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Set number of output classes\n",
    "model.conv1 = nn.Conv2d(in_channels=3,\n",
    "                        out_channels=64,\n",
    "                        kernel_size=(7,7),\n",
    "                        stride=(2,2),\n",
    "                        padding=(3,3),\n",
    "                        bias=False)\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "out_features = 20\n",
    "model.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training method\n",
    "def train(net, optim, train_loader):\n",
    "    net.train()\n",
    "    for image_cpu, label_cpu in tqdm(train_loader):\n",
    "        # Move image and label to GPU\n",
    "        image = image_cpu.to(device)\n",
    "        label = label_cpu.to(device)\n",
    "        \n",
    "        # Clear gradient\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Forward through the network\n",
    "        output = net(image)\n",
    "        \n",
    "        # Loss and gradient\n",
    "        loss = torch.nn.functional.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update paramters\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation method\n",
    "def evaluate(net, val_loader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    \n",
    "    for image_cpu, label_cpu in tqdm(val_loader):\n",
    "        # Move image and label to GPU\n",
    "        image = image_cpu.to(device)\n",
    "        label = label_cpu.to(device)\n",
    "        \n",
    "        # Don't track gradients for performance in evaluation\n",
    "        with torch.no_grad():\n",
    "            # Get prediction with forward pass\n",
    "            prediction = net(image).argmax(dim=-1)\n",
    "            \n",
    "            # Total number in batch\n",
    "            total += image.size(0)\n",
    "            \n",
    "            # Number correct in batch\n",
    "            correct += (prediction == label).sum().item()\n",
    "            \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "num_epochs = 12\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "best_state_dict = {}\n",
    "best_val_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    val_acc = evaluate(model, letters_val_loader) * 100\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "    print(\"Epoch {}: {}%\".format(epoch, val_acc))\n",
    "    train(model, optimizer, letters_train_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch % 4 == 0 and epoch != 0:\n",
    "        torch.save(best_state_dict, \"./models/letter_shifts_class732_lr01_epoch\" + str(epoch))\n",
    "    \n",
    "print(\"Done! {}%\".format(evaluate(model, letters_val_loader) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(best_state_dict, \"./models/letter_shifts_class732_lr01_epoch12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing data from directory\n",
    "letters_val = torchvision.datasets.ImageFolder(root=\"./data/text_val\",\n",
    "                                               transform=transform)\n",
    "\n",
    "\n",
    "letters_val_loader = torch.utils.data.DataLoader(dataset=letters_val,\n",
    "                                                 batch_size=512,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=4,\n",
    "                                                 pin_memory=True)\n",
    "\n",
    "# Initialize model\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "# model = torchvision.models.resnet50(pretrained=False)\n",
    "\n",
    "# Set number of output classes\n",
    "model.conv1 = nn.Conv2d(in_channels=3,\n",
    "                        out_channels=64,\n",
    "                        kernel_size=(7,7),\n",
    "                        stride=(2,2),\n",
    "                        padding=(3,3),\n",
    "                        bias=False)\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "out_features = 26\n",
    "model.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"./models/letter_model_lr01_gamma015_e12\"))\n",
    "\n",
    "val_acc = evaluate(model, letters_val_loader) * 100\n",
    "print(\"Done!\", val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
